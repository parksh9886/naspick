import json
import sys

# Load data
try:
    with open(r'c:\Users\sec\Desktop\Naspick\data\data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
except Exception as e:
    print(f"Error loading data: {e}")
    sys.exit(1)

def generate_report(stock):
    name = stock.get('name', stock['ticker'])
    ticker = stock['ticker']
    score = stock.get('final_score', 0)
    tier = stock.get('tier', 3)
    sector = stock.get('sector', 'Unknown')
    
    stats = stock.get('score_breakdown', {})
    growth = stats.get('growth', 0) * 10 
    value = stats.get('value', 0) * 10
    stability = stats.get('stability', 0) * 10
    
    # Normalize stats if they are small numbers (some versions of data might be 0-10 or 0-100)
    # Based on previous view_file, score_breakdown seems to be small numbers summing to final_score?
    # Let's check stats_bar which is 0-100
    stats_bar = stock.get('stats_bar', {})
    growth_score = stats_bar.get('fundamentals', 50) # Using fundamentals as proxy for growth for now if growth specific is missing
    # Actually data.json has 'score_breakdown' with 'growth', 'value' etc. but let's see values.
    # In previous turn: "growth": 16.9 (out of ~20 max likely? or is it contribution?)
    # "stats_bar": "fundamentals": 83, "value": 63... This is 0-100. Let's use stats_bar.
    
    s_growth = stats_bar.get('fundamentals', 50) # mapping fundamentals -> growth roughly
    s_value = stats_bar.get('value', 50)
    s_stability = stats_bar.get('stability', 50)
    s_momentum = stats_bar.get('momentum', 50)
    s_risk = stats_bar.get('risk', 50) # Note: Low risk score usually means High Risk? Or High Score means Low Risk?
    # In data.json: SYF risk: 11 (Low score probably means Low Stability i.e. High Risk? or Low Volatility?)
    # Let's assume stats_bar is "Higher is Better" usually, but for Risk?
    # Actually SYF: stability 85, risk 11. 
    # Let's check logic: usually "Risk Score" in these apps: High Score = Safe? or High Score = Risky?
    # Let's infer from context. "High Risk" usually implies high volatility.
    
    consensus = stock.get('consensus', {})
    target_price = consensus.get('target_price', {})
    upside = 0
    if target_price and target_price.get('mean') and stock['current_price']:
        upside = ((target_price['mean'] - stock['current_price']) / stock['current_price']) * 100
        
    rsi = stock.get('technical_analysis', {}).get('rsi', {}).get('value', 50)
    
    # --- Generation Logic ---
    report = []
    
    # 1. Identity & Trend
    tier_str = f"{tier}í‹°ì–´" if tier else "ë¶„ì„ì¤‘ì¸"
    # --- SEO Keyword Injection ---
    # --- Generation Logic (Natural Analyst Style) ---
    report = []
    
    # Phase 1: Intro (Identity & Trend)
    # Natural phrasing: "Based on AI analysis, [Name] is currently..."
    tier_desc = "ìµœìƒìœ„ê¶Œ(1í‹°ì–´)" if tier == 1 else "ìƒìœ„ê¶Œ" if tier <= 2 else "ì¤‘ìœ„ê¶Œ" if tier <= 3 else "í•˜ìœ„ê¶Œ"
    trend_desc = "ê°•í•œ ìƒìŠ¹ì„¸ë¥¼ íƒ€ê³  ìˆìŠµë‹ˆë‹¤" if s_momentum > 80 else "ì•ˆì •ì ì¸ íë¦„ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤" if s_momentum > 50 else "ì¡°ì •ì´ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤"
    
    intro = f"**{name}({ticker})**ì˜ AI ë¶„ì„ ê²°ê³¼, í˜„ì¬ **{sector} ì„¹í„° ë‚´ {tier_desc}**ì— ìœ„ì¹˜í•˜ë©° {trend_desc}."
    report.append(intro)
    
    # Phase 2: Fundamental Context (The "Why")
    # Focus on the strongest point naturally
    sorted_traits = sorted([('ì„±ì¥ì„±', s_growth), ('ë°¸ë¥˜ì—ì´ì…˜', s_value), ('ì¬ë¬´ì•ˆì •ì„±', s_stability)], key=lambda x: x[1], reverse=True)
    best_trait = sorted_traits[0]
    worst_trait = sorted_traits[-1]
    
    trait_msg = ""
    if best_trait[1] >= 80:
        trait_msg = f"íŠ¹íˆ **{best_trait[0]}({best_trait[1]}ì )** ë¶€ë¬¸ì—ì„œ **ë§¤ìš° ìš°ìˆ˜í•œ í‰ê°€**ë¥¼ ë°›ì•„,"
        if best_trait[0] == 'ì„±ì¥ì„±':
            trait_msg += " ë¯¸ë˜ ì‹¤ì  ê¸°ëŒ€ê°ì´ ì£¼ê°€ì— ë°˜ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        elif best_trait[0] == 'ë°¸ë¥˜ì—ì´ì…˜':
            trait_msg += " í˜„ì¬ ì£¼ê°€ëŠ” **ì €í‰ê°€ ë§¤ë ¥**ì´ ë†’ì€ êµ¬ê°„ì…ë‹ˆë‹¤."
        else:
            trait_msg += " ë¶ˆí™•ì‹¤í•œ ì‹œì¥ì—ì„œë„ ì•ˆì •ì ì¸ ë°©ì–´ë ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    elif best_trait[1] >= 60:
        trait_msg = f"í€ë”ë©˜í„¸ ì¸¡ë©´ì—ì„œëŠ” **{best_trait[0]}** ì§€í‘œê°€ ì–‘í˜¸í•˜ë©° ì „ë°˜ì ìœ¼ë¡œ ê· í˜• ì¡íŒ ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤."
    else:
        trait_msg = "ë‹¤ë§Œ ì „ë°˜ì ì¸ í€ë”ë©˜í„¸ ëª¨ë©˜í…€ì€ ë‹¤ì†Œ ì•½í•œ êµ¬ê°„ì„ ì§€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤."
        
    report.append(trait_msg)
    
    # Phase 3: Market Pulse (Consensus + Technicals)
    market_msg = ""
    if upside > 10:
        market_msg = f"ì›”ê°€ ì—­ì‹œ **ê¸ì •ì **ì…ë‹ˆë‹¤. ëª©í‘œ ì£¼ê°€ëŠ” í˜„ì¬ë³´ë‹¤ **{upside:.1f}% ë†’ì€ ìˆ˜ì¤€**ì´ë©°,"
    elif upside > -5:
        market_msg = f"ì›”ê°€ ì»¨ì„¼ì„œìŠ¤ëŠ” í˜„ì¬ ì£¼ê°€ë¥¼ **ì ì • ìˆ˜ì¤€**ìœ¼ë¡œ í‰ê°€í•˜ê³  ìˆìœ¼ë©°,"
    else:
        market_msg = f"ì›”ê°€ëŠ” í˜„ì¬ ì£¼ê°€ê°€ ë‹¨ê¸°ì ìœ¼ë¡œ **ê³ í‰ê°€**ë˜ì—ˆë‹¤ê³  íŒë‹¨í•˜ê³  ìˆìœ¼ë‚˜,"
        
    # RSI & MACD Logic (Context-Aware)
    has_macd_gc = 'MACD_GoldenCross' in stock.get('signals', [])
    
    if rsi < 30:
        if has_macd_gc:
            market_msg += f" ê¸°ìˆ ì ìœ¼ë¡œëŠ” **ê³¼ë§¤ë„(RSI {rsi:.1f})** ìƒíƒœì´ë‚˜, **MACD ê³¨ë“ í¬ë¡œìŠ¤**ê°€ ë°œìƒí•˜ì—¬ **ê°•ë ¥í•œ ë°˜ë“±**ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤."
        else:
            market_msg += f" ê¸°ìˆ ì ìœ¼ë¡œëŠ” **ê³¼ë§¤ë„(RSI {rsi:.1f})** ìƒíƒœë¼ **ë°˜ë“± ê°€ëŠ¥ì„±**ì´ ë†’ìŠµë‹ˆë‹¤."
    elif rsi > 70:
        if has_macd_gc:
            market_msg += f" ê¸°ìˆ ì ìœ¼ë¡œ **ê³¼ì—´(RSI {rsi:.1f})** ì‹ í˜¸ê°€ ìˆìœ¼ë‚˜, **MACD ê³¨ë“ í¬ë¡œìŠ¤**ê°€ ë°œìƒí•˜ì—¬ **ìƒìŠ¹ ì¶”ì„¸ê°€ ì§€ì†**ë  ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤."
        else:
            market_msg += f" ê¸°ìˆ ì ìœ¼ë¡œ **ê³¼ì—´(RSI {rsi:.1f})** ì‹ í˜¸ê°€ ìˆì–´ ë‹¨ê¸°ì ì¸ ìˆ¨ê³ ë¥´ê¸°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    else:
        if has_macd_gc:
            market_msg += f" ê¸°ìˆ ì  ì§€í‘œëŠ” ì•ˆì •ì ì´ë©°, íŠ¹íˆ **MACD ê³¨ë“ í¬ë¡œìŠ¤**ê°€ ë°œìƒí•˜ì—¬ **ìƒìŠ¹ ëª¨ë©˜í…€**ì´ ê°•í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        else:
            market_msg += f" ê¸°ìˆ ì  ì§€í‘œë“¤ë„ íŠ¹ì´ì‚¬í•­ ì—†ì´ ì•ˆì •ì ì…ë‹ˆë‹¤."
            
    report.append(market_msg)
    
    # Phase 4: Conclusion (Verdict)
    # Simple, clean verdict
    conclusion = ""
    if score >= 75:
        conclusion = "ì¢…í•©ì ìœ¼ë¡œ **íˆ¬ìë¥¼ ì ê·¹ ê³ ë ¤í•´ë³¼ ë§Œí•œ ì‹œì **ì…ë‹ˆë‹¤."
    elif score >= 50:
        conclusion = "ì¢…í•©ì ìœ¼ë¡œ **ì§€ì¼œë³¼ ë§Œí•œ ì¢…ëª©**ì´ë‚˜, ë¶„í•  ë§¤ìˆ˜ë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
    else:
        conclusion = "ì¢…í•©ì ìœ¼ë¡œ ì‹ ê·œ ì§„ì…ë³´ë‹¤ëŠ” **ê´€ë§í•˜ë©° ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬**í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
        
    report.append(conclusion)
    
    return " ".join(report)

# Select samples
samples = []
# 1. Top Rank
samples.extend([d for d in data if d.get('rank', 999) <= 3])
# 2. Some popular ones
popular_tickers = ['NVDA', 'TSLA', 'AAPL', 'AMD', 'PLTR', 'SOXL', 'TQQQ'] # Note: ETFs might not be in data.json or might lack some fields
for t in popular_tickers:
    found = next((d for d in data if d['ticker'] == t), None)
    if found and found not in samples:
        samples.append(found)

# 3. Low Tier/Score
low_score = [d for d in data if d.get('final_score', 0) < 40][:2]
samples.extend(low_score)

# Deduplicate
unique_samples = {s['ticker']: s for s in samples}.values()

print("=== AI Report Samples (Simulation) ===\n")
for s in list(unique_samples)[:10]:
    print(f"ğŸ“Œ {s['ticker']} (Score: {s.get('final_score')})")
    print(f"ğŸ“ {generate_report(s)}")
    print("-" * 50 + "\n")
