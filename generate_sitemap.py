import json
import datetime
import os

# 1. ì‚¬ì´íŠ¸ ê¸°ë³¸ ì£¼ì†Œ (ë³¸ì¸ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½ í•„ìˆ˜!)
BASE_URL = "https://naspick.com"

def generate_sitemap():
    print("ğŸ—ºï¸ Generating Sitemap & Robots.txt...")

    # 2. ì¢…ëª© ë°ì´í„° ì½ê¸°
    try:
        with open('data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print("âŒ data.json not found!")
        return

    # 3. XML í—¤ë” ì‘ì„±
    xml_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    xml_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'

    # 4. ë©”ì¸ í˜ì´ì§€ ì¶”ê°€
    today = datetime.date.today().isoformat()
    xml_content += f"""
    <url>
        <loc>{BASE_URL}/index.html</loc>
        <lastmod>{today}</lastmod>
        <changefreq>daily</changefreq>
        <priority>1.0</priority>
    </url>
    """

    # 5. ê° ì¢…ëª©ë³„ ìƒì„¸ í˜ì´ì§€ URL ì¶”ê°€ (Clean URL ì ìš©)
    for item in data:
        ticker = item.get('ticker')
        if ticker:
            # íŠ¹ìˆ˜ë¬¸ì(&) ì²˜ë¦¬ (URL ì¸ì½”ë”©)
            safe_ticker = ticker.replace("&", "&amp;")
            # Vercel Rewrite ì ìš©ëœ Clean URL
            url = f"{BASE_URL}/stock/{safe_ticker}"
            
            xml_content += f"""
    <url>
        <loc>{url}</loc>
        <lastmod>{today}</lastmod>
        <changefreq>daily</changefreq>
        <priority>0.8</priority>
    </url>"""

    xml_content += '\n</urlset>'

    # 6. Sitemap ì €ì¥
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(xml_content)
    
    print(f"âœ… Sitemap generated with {len(data) + 1} URLs.")

    # 7. Robots.txt ìƒì„±
    robots_content = f"""User-agent: *
Allow: /

Sitemap: {BASE_URL}/sitemap.xml
"""
    with open('robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("âœ… robots.txt generated.")

if __name__ == "__main__":
    generate_sitemap()
